\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,bm}
\usepackage{graphicx}
\usepackage[numbers]{natbib}
\usepackage{textcomp} % Degree symbol
\usepackage{placeins} % Float barrier
\usepackage{subcaption} % To use subfigures with subcaptions
 
\newcommand{\omegai}{\boldsymbol{\omega_i}}
\newcommand{\omegar}{\boldsymbol{\omega_r}}
\newcommand{\tb}{\mathbf{t}}
 
\begin{document}
  
\title{Task 4. Cloth Rendering}
\author{Garoe Dorta-Perez\\
CM50245: Computer Animation and Games II}
 
\maketitle
 
\section{Introduction}

Rendering realistic images is a challenging task, specially if there are memory or time constrains for the computation.
Cloth is a complex material composed of interwoven threads of different types.
Moreover, its appearance can vary from diffuse to highly specular.

\section{Previous work}

Solving for global illumination generally involves providing a solution to the rendering equation \cite{Kajiya1986}.
One of the earliest approaches was based on simple empirical shading models \cite{Weft1986}.
The main objective was to accomplish believable shading, disregarding physical accuracy.
Ever since, an increasing number of methods have been proposed, this techniques can be broadly divided into two groups, data-based models and procedural models.

The data-based approach focuses on collecting reflectance information, that will be later used to model the cloth.
Bidirectional Texture Function (BTF) \cite{Dana1999} is a function that is often used to sampled in the data based techniques.
\cite{Sattler2003} captured BTF from a rectangular probed and generated view-dependant texture-maps for the cloth.
\citeauthor{Wang2008} \cite{Wang2008} proposed a variation of the previous technique, the authors modeled the captured data as a microfacet-based BRDF to which they fitted a normal distribution function for each facet.
Within the data-based models, a volumetric method was proposed by \citeauthor{Zhao2011} \cite{Zhao2011}.
The authors capture a X-ray computed tomography (CT) scanner of the fabric, which is later matched to images of the same material.

Geometric models focus on simulation the micro-geometry of the cloth in conjunction with global illumination.
The light scattering is simulated for each fibre in the thread, where the fibres are modelled as perfect cylinders.
To be able to model the the complete scattering effects on a surface, Bidirectional Scattering-Surface Reflectance Distribution Function (BSSRDF) \cite{NicodemusFredEandRichmond1977} have been used.
With this function, complex light phenomena like subsurface scattering are modelled.

Procedural techniques emphasise on improving previous BRDF models in order to simulate cloth appearance realistically.
\citeauthor{Kang2010} \cite{Kang2010} proposed a procedural method which models the reflectance of woven fabric using an alternating anisotropy and deformed microfacet distribution.
A weft or warp anisotropic function is computed for each fragment which has been previously classified into one of the two groups.
A model with focus on accurately handling specular reflections was proposed by \citeauthor{Irawan2012} \cite{Irawan2012}.
The authors' model does not required image data and it relies on textures for close up views.

A survey of physically-based methods in cloth simulations was presented by \citeauthor{Schroder2012} \cite{Schroder2012}, we also refer the readers to \citeauthor{Yuen2011}'s \cite{Yuen2011} survey for example-based and procedural-based techniques.

\section{Methodology}

In this section we will discus in detail the theoretical and practical aspects of the chosen paper.

\subsection{Light scattering model}
\label{sec:light_scattering_model}
We have chosen to implement a recent paper \cite{Sadeghi2013} which presents a microcylinder based model for fast and realistic cloth rendering.
The authors propose a model of fabric based on two microcylinders oriented in two orthogonal directions, as shown in Figure \ref{fig:microcylinders}.
\citeauthor{Sadeghi2013} define the reflectance model for a single thread in the fabric as

\begin{figure}[ht!]
\begin{minipage}[b]{.45\textwidth}
\centering
\includegraphics[width=1\textwidth]{images/microcylinders}
	\caption{\citeauthor{Sadeghi2013} shading model \cite{Sadeghi2013}, where $\omegai$ is the incident light direction, $\mathbf{n}$ is the surface normal and $\mathbf{t_1},\mathbf{t_2}$ are the orthogonal thread directions.}
	\label{fig:microcylinders}
\end{minipage}
\hfill
\begin{minipage}[b]{.45\textwidth}
\centering
\includegraphics[width=1\textwidth]{images/cloth_directions}
	\caption{\citeauthor{Sadeghi2013} shading model \cite{Sadeghi2013}, showing $\theta$ and $\phi$ angles given a pair of directions $\omegai$ and $\omegar$.}
	\label{fig:cloth_directions}
\end{minipage}
\end{figure}

\begin{equation}
L_r = \int \frac{\left(f_{r,s}(\tb, \omegai, \omegar) + f_{r,v}(\tb,\omegai,\omegar)\right)L_i(\omegai)\cos(\theta_i)\delta \omegai}{\cos^2(\theta_d)},
\label{eq:full_model}
\end{equation}

where $\tb$ is the thread direction, $\omegai$ is the ray incoming direction, $\omegar$ is the ray outgoing direction, $\theta_i, ~\theta_r, ~ \phi_i \mbox{ and } \phi_r$ are angles as shown in Figure \ref{fig:cloth_directions},  $\theta_d = \theta_i-\theta_r$ and $L_i$ is the incoming irradiance in the evaluated point.
Note that radiometric notation \cite{Marschner2003} is used to define $L_r$, which represents the outgoing radiance over a infinitesimal arc length of the cylinder and how the integral extends over the entire sphere instead of the typical hemisphere.

The surface reflection term in Equation \ref{eq:full_model} is defined as

\begin{equation}
f_{r,s}(\tb, \omegai, \omegar) = F_r(\eta, \omegai) \cos(\phi_d/2)g(\gamma_s, \theta_h),
\end{equation}

where $\theta_h = (\theta_i+\theta_r)/2$, $\phi_d = \phi_i-\phi_r$, $F_r$ is a Fresnel reflection term that is computed using \citeauthor{Schlick1994}'s approximation \cite{Schlick1994} $F_r(\eta, \omegai) = \eta + (1 - \eta)(1 - \mathbf{h} \cdot \omegai)^5$ where $\cdot$ is the vector dot product operator, $\mathbf{h} = (\omegai + \omegar)/ \left|\omegai + \omegar \right|$ is the normalized halfway vector, $\eta$ is the reflectance for $\mathbf{h} \cdot \omegai = 1$, $g(\gamma, \theta) = \gamma \mathrm{e} ^{\mathbf{j} \cdot \mathbf{q}-1}$ is a Gaussian lobe \cite{Wang2009} where $\mathbf{q}$ is the lobe axis, the direction $\mathbf{j}$ is the spherical parameter in the resulting function and $\gamma$ is the amplitude.

The volume scattering term in Equation \ref{eq:full_model} is defined as

\begin{equation}
f_{r,v}(\tb,\omegai,\omegar) = F_t(\eta, \omegai) F_t(\eta', \omegar') \frac{(1-k_d)g(\gamma_v, \theta_h)+k_d}{\cos(\theta_i) + \cos(\theta_r)} \mathbf{k_a},
\end{equation}

where $k_d$ is a scattering constant, $\mathbf{k_a}$ is an rgb albedo constant vector, $F_t = 1 - F_r$ is a Fresnel transmission term, $\omegar'$ is a projection of $\omegar$ into a plane that contains the normal $\mathbf{n}$ and $\eta'$ is computed using the Bravais index \cite{Marschner2003} as $\eta'(m) = \sqrt{\eta^2 - sin^2(m)}  / \cos(m)$ where $m$ is the angle between $\omegar$ and its projection $\omegar'$.

The outgoing radiance in the path shown in Figure \ref{fig:cloth_directions} is

\begin{equation}
L_r(\omegar) = a_1 L_{r,1}(\omegar) + a_2 L_{r,2}(\omegar),
\end{equation}

where $a_1$ and $a_2$ are the area coverage ratio for the first and second thread within the patch, in our case we assume a watertight pattern of equally size threads, leading to $a_1 = a_2 = 0.5$, $L_1$ and $l_2$ are the outgoing radiances for the first and second thread computed as shown in Equation \ref{eq:full_model}.

In order to compute a thread direction $\tb$ without using external data structures, we follow a fixed texture axis as shown in Figure \ref{fig:thread_uv_coord}.
Given an intersection point in a triangle $\mathbf{p} = \left[ x_p, y_p,z_p \right]$ and its texture coordinates $\mathbf{u} = \left[ u_p, v_p \right]$.
We define $\tb$ vector as the vector $\tb = (\hat{\mathbf{p}} - \mathbf{p})/ \left|\hat{\mathbf{p}} + \mathbf{p} \right|$ such that $\hat{\mathbf{p}}$ texture coordinates are $\hat{\mathbf{u}} = \left[ u_p + 1, v_p \right]$.
In our shader we can easily compute the texture coordinates of the triangle vertices, however we can not immediately get a world position from a new texture coordinate.
Assuming that the 3d to texture transformation is an affine matrix $T$,

\begin{equation}
\mathbf{u} T = \mathbf{p} \rightarrow
\begin{pmatrix}
u & v
\end{pmatrix}
\begin{pmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23}
\end{pmatrix} =
\begin{pmatrix}
x & y & z
\end{pmatrix}
\label{eq:uv_to_3d}
\end{equation}

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.8\textwidth]{images/thread_3d_coord}
	\caption{To compute the vector $\tb$, we follow the texture coordinates of the intersection point $\mathbf{p}$.}
	\label{fig:thread_uv_coord}
\end{figure}

The system in Equation \ref{eq:uv_to_3d} has six unknowns and three equations, therefore we need two pairs of world points - texture coordinates to solve $T$.
Writing out the terms for two known points $\mathbf{p}_1$ and $\mathbf{p}_2$ in the triangle,

\begin{equation}
\begin{split}
x_1 = u_1 a_{11} + v_1 a_{21}, \quad y_1 = u_1 a_{12} + v_1 a_{22}, \quad z_1 = u_1 a_{13} + v_1 a_{23},\\
x_2 = u_2 a_{11} + v_2 a_{21}, \quad y_2 = u_2 a_{12} + v_2 a_{22}, \quad z_2 = u_2 a_{13} + v_2 a_{23}.
\end{split}
\end{equation}

Solving for each term analytically,

%a &= \frac{x_1 - v_1 d}{u_1} \quad a = \frac{x_2 - v_2 d}{u_2} \\
\begin{align}
a_{21}& = \frac{u_2 x_1 - u_1 x_2}{u_2 v_1 - u_1 v_2},& a_{22}& = \frac{u_2 y_1 - u_1 y_2}{u_2 v_1 - u_1 v_2},& a_{23}& = \frac{u_2 z_1 - u_1 z_2}{u_2 v_1 - u_1 v_2}, \\
a_{11}& = \frac{x_1 - v_1 a_{21}}{u_1},& a_{12}& = \frac{y_1 - v_1 a_{22}}{u_1},&  a_{13}& = \frac{z_1 - v_1 a_{23}}{u_1}.
\end{align}

Notice that the term of $1/(u_2 v_1 - u_1 v_2)$ is shared, so it can be precomputed in order to increase performance.
The aforementioned method will give $\tb_1$, for $\tb_2$ the process is equivalent with the exception that $\hat{\mathbf{u}}$ will be incremented on the $v$ direction, $\hat{\mathbf{u}} = \left[ u_p, v_p + 1\right]$.

\subsection{Shading model}
\label{sec:shading_model}

In order to render cloth fabrics the authors evaluate the outgoing radiance from each patch, which is assumed to be locally flat and smaller than a pixel in the image.
This patch is defined as the smallest thread weaving patter such that the fabric can be constructed by repeating this patch, as shown in Figure~\ref{fig:tanget_curve}.
For each thread in the patch a tangent curved is defined, this curve will be sampled at fixed positions giving the normal direction in that position, as shown in Figure~\ref{fig:tanget_curve}.
The BRDF will be evaluated for each sample and the total outgoing radiance will be computed as follows,

\begin{equation}
L_{r}(\omegar) = \frac{1}{N_j} \sum_\tb \int L_i(\omegai) f_s(\tb, \omegai, \omegar) \cos \theta_i d \omegai,
\label{eq:path_lr}
\end{equation}

where $N_j$ is the number of samples.

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.7\textwidth]{images/tanget_curve}
	\caption{Weaving pattern and tangent curves: (top left) a weaving pattern example, (bottom left) the smallest patch, (top right) tangent curve for the blue thread in the smallest patch, (bottom right) tangent curve for the orange thread in the smallest patch, arrows indicate a normal sampled at that point, image taken from \cite{Sadeghi2013}.}
	\label{fig:tanget_curve}
\end{figure}

\citeauthor{Sadeghi2013} also add a shadowing and masking term to improve the quality of their results, the authors add a new term that will account for threads occluding each other depending on the viewing direction.
The effect of the masking term will be specially relevant at grazing angle viewing and lighting directions.
In Equation~\ref{eq:path_lr} the term $f_s(\tb, \omegai, \omegar)$ will be multiplied by $M(\tb, \omegai, \omegar)$ such that,

\begin{equation}
\begin{split}
M(\tb, \omegai, \omegar) =& (1 - u(\phi_d)) \max(\cos(\phi_i), 0) \times \max(\cos(\phi_r), 0) + \\
& u(\phi_d) \min( \max(\cos(\phi_i), 0), \max(\cos(\phi_r), 0) ),
\end{split}
\end{equation}

where $\times$ is the vector cross product operator, $u$ is a unit height Gaussian function with standard deviation between $15$\textdegree and $25$\textdegree; an in depth discussion on how to compute $u$ can be found in \citeauthor{Ashikmin2000} \cite{Ashikmin2000} Section 4.2 New Shadowing Term.

The authors add a reweighting factor to account for $\omegai$ and $\omegar$ being too far from $n$.
By projecting the thread length in the direction of the viewer, tangents that are more visible for the viewer will have a greater contribution.
The reweighting factor $P(\tb, \omegai, \omegar)$ will be computed as follows,

\begin{equation}
\begin{split}
P(\tb, \omegai, \omegar) =& (1 - u(\Psi_d)) \max(\cos(\Psi_i), 0) \times \max(\cos(\Psi_r), 0) + \\
& u(\Psi_d) \min( \max(\cos(\Psi_i), 0), \max(\cos(\Psi_r), 0) ),
\end{split}
\end{equation}

where $\Psi$ are the angles between $\mathbf{n}$ and the projection of $\boldsymbol{\omega}$ into the plane that contains $\tb$ and $\mathbf{n}$, as shown in Figure~\ref{fig:psi_thread_angles}.

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.4\textwidth]{images/psi_thread_angles}
	\caption{$\Psi$ angles in the thread for a given $\omegai$ and $\omegar$, image taken from \cite{Sadeghi2013}.}
	\label{fig:psi_thread_angles}
\end{figure}

There is also a normalization factor $Q$ to account for the number of samples and for weaving patterns that are not water tight,

\begin{equation}
Q = \frac{a_1}{N_1} \sum_\tb P(\tb, \omegai, \omegar) + \sum_\tb P(\tb, \omegai, \omegar) + (1 - a_1 - a_2)(\omegar \cdot \mathbf{n}),
\end{equation}

where $N_1$ and $N_2$ are the number of samples of each thread direction.

Finally, the complete model for the outgoing radiance is

\begin{equation}
L_{r}(\omegar) = \frac{1}{Q N_j} \sum_\tb \int L_i(\omegai) f_s(\tb, \omegai, \omegar) M(\tb, \omegai, \omegar) P(\tb, \omegai, \omegar)  \cos \theta_i d \omegai.
\end{equation}

\subsection{Other implementation considerations}

In order to compute more easily quantities such as the $\theta$ or $\phi$ angles introduced in the previous section, we will defined a new coordinate system with the vectors $\left\lbrace \tb,\mathbf{n},\mathbf{s} \right\rbrace$, whose centre will be the triangle ray-intersection point $\mathbf{p}$, where $\mathbf{s}$ is a normalized vector $\mathbf{s} = \mathbf{n} \times \tb$.
The matrix that will transform from world coordinates to this system is

\begin{equation}
M = M_{trans}M_{rot} =
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
-p_x & -p_y & -p_z & 1 \\
\end{pmatrix}
\begin{pmatrix}
t_x & n_x & s_x & 0 \\
t_y & n_y & s_y & 0 \\
t_z & n_z & s_z & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix},
\end{equation}

such that $\mathbf{x}M=\mathbf{x}'_{new}$, where $\mathbf{x}$ is the original row vector in homogeneous coordinates and $\mathbf{x}'_{new}$ is the transformed vector.

We decided to implement the shader in Maya's\textsuperscript\textregistered Mental Ray\textsuperscript\textregistered rendering software.
The rationale under this choice lays in the advantages of integrating work in a established framework, which allows us to easily use the shader for a dynamic cloth simulation.
Mental Ray\texttrademark approximates \citeauthor{Kajiya1986}'s equation \cite{Kajiya1986} using photon mapping \cite{Jensen1996}.
Our approach is to compute an initial estimate of the outgoing radiance $L_{ri}$ for each direct hit during the raytracing path.
In the photon map construction stage each photon hit will locally sample $L_{ri}$ using Equation \ref{eq:full_model}, from this samples an average irradiance will be evaluated, which will then be added to the initial estimate as shown below

\begin{equation}
L_r = L_{ri} + \sum_{i = 1}^{I} \psi_i L_{ri},
\end{equation}

where $I$ is the total number of photons inside a fixed radius around $\mathbf{p}$ and $\psi_i$ is the normalized flux of the ith photon, which is computed from an initial arbitrary flux shared by all photons and decreases with an absorption rate per bounce.

\section{Results}

We have implemented the basic light scattering model in Mental Ray\textsuperscript\textregistered.
To better understand the effects of the different terms in the BRDF, results for the different parts are evaluated separately.
The cloth rendered using only the volume scattering term in shown in Figure~\ref{fig:scatter_only}, using only the reflection term is shown in Figure~\ref{fig:reflect_only_x5}, note that for visualization purposes the reflection term has been increased by a factor of 5.
Lastly, a rendered image for the fabric using both terms is shown in Figure~\ref{fig:full_model}.

\begin{figure}[htbp!]
        \centering
        \begin{subfigure}[t]{0.48\textwidth}
                \includegraphics[width=\textwidth]{images/scatter_only}
                \caption{Effect of the volume scattering term.}
                \label{fig:scatter_only}
        \end{subfigure}
        \begin{subfigure}[t]{0.48\textwidth}
                \includegraphics[width=\textwidth]{images/reflect_only_x5}
                \caption{Effect of the reflection term, scaled by 5 improve visualization.}
                \label{fig:reflect_only_x5}
        \end{subfigure}
        \caption{Evaluating the effects of the different terms of the BRDF.}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=0.8\textwidth]{images/full_model}
	\caption{Final result.}
	\label{fig:full_model}
\end{figure}

\FloatBarrier
\section{Conclusion and Future Work}

Our implementation only includes the basic light scattering proposed by the authors \cite{Sadeghi2013}; so a evident line of future work would be to add the remaining features from the paper into our code.
\citeauthor{Sadeghi2013} model works under the assumption that the cloth patches are smaller than a pixel in the image, this leads to incorrect render images at close ups.
Another drawback of the model is the optimization of parameters, being so complex that they have to be adjusted manually.
How to efficiently apply importance sampling to reduce the rendering times and increase quality, has been addressed with several extensions to the original paper \cite{Wang2014, Mizutani2014}.
%Another drawback of this model is a complicated application of parameter optimization techniques; therefore, derivation of appropriate parameters of individual threads is left completely to users and their experience.

%All these methods mainly focus on developing a comprehensive reflectance model for cloth fabrics and do not propose an efficient rendering method of cloth fabrics under environment lighting

%The main difficulty of interactive cloth rendering resides in the integral of high-frequency complex functions, previous method limit it to a simple lighting model.

%These methods can simulate the appearance of complex highlights and color shifts which cannot be fully handled by pure analytical models. 
%However, the main disadvantage of these models is the need to express the structure of the materials which leads to the description of a specific kind of materials. 
%All the analytical methods use the exact above procedure to represent the material reflection properties and in the process part of the reflection information gets lost.

\newpage
\bibliographystyle{plainnat}
\bibliography{t4_report}

\end{document}

